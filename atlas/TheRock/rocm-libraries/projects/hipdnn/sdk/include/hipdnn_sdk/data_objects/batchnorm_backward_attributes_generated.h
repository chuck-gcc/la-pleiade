// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_BATCHNORMBACKWARDATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_
#define FLATBUFFERS_GENERATED_BATCHNORMBACKWARDATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&
              FLATBUFFERS_VERSION_MINOR == 9 &&
              FLATBUFFERS_VERSION_REVISION == 23,
             "Non-compatible flatbuffers version included");

namespace hipdnn_sdk {
namespace data_objects {

struct BatchnormBackwardAttributes;
struct BatchnormBackwardAttributesBuilder;
struct BatchnormBackwardAttributesT;

bool operator==(const BatchnormBackwardAttributesT &lhs, const BatchnormBackwardAttributesT &rhs);
bool operator!=(const BatchnormBackwardAttributesT &lhs, const BatchnormBackwardAttributesT &rhs);

struct BatchnormBackwardAttributesT : public ::flatbuffers::NativeTable {
  typedef BatchnormBackwardAttributes TableType;
  int64_t dy_tensor_uid = 0;
  int64_t x_tensor_uid = 0;
  ::flatbuffers::Optional<int64_t> mean_tensor_uid = ::flatbuffers::nullopt;
  ::flatbuffers::Optional<int64_t> inv_variance_tensor_uid = ::flatbuffers::nullopt;
  int64_t scale_tensor_uid = 0;
  std::vector<int64_t> peer_stats_tensor_uid{};
  int64_t dx_tensor_uid = 0;
  int64_t dscale_tensor_uid = 0;
  int64_t dbias_tensor_uid = 0;
};

struct BatchnormBackwardAttributes FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
  typedef BatchnormBackwardAttributesT NativeTableType;
  typedef BatchnormBackwardAttributesBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_DY_TENSOR_UID = 4,
    VT_X_TENSOR_UID = 6,
    VT_MEAN_TENSOR_UID = 8,
    VT_INV_VARIANCE_TENSOR_UID = 10,
    VT_SCALE_TENSOR_UID = 12,
    VT_PEER_STATS_TENSOR_UID = 14,
    VT_DX_TENSOR_UID = 16,
    VT_DSCALE_TENSOR_UID = 18,
    VT_DBIAS_TENSOR_UID = 20
  };
  int64_t dy_tensor_uid() const {
    return GetField<int64_t>(VT_DY_TENSOR_UID, 0);
  }
  bool mutate_dy_tensor_uid(int64_t _dy_tensor_uid = 0) {
    return SetField<int64_t>(VT_DY_TENSOR_UID, _dy_tensor_uid, 0);
  }
  int64_t x_tensor_uid() const {
    return GetField<int64_t>(VT_X_TENSOR_UID, 0);
  }
  bool mutate_x_tensor_uid(int64_t _x_tensor_uid = 0) {
    return SetField<int64_t>(VT_X_TENSOR_UID, _x_tensor_uid, 0);
  }
  ::flatbuffers::Optional<int64_t> mean_tensor_uid() const {
    return GetOptional<int64_t, int64_t>(VT_MEAN_TENSOR_UID);
  }
  bool mutate_mean_tensor_uid(int64_t _mean_tensor_uid) {
    return SetField<int64_t>(VT_MEAN_TENSOR_UID, _mean_tensor_uid);
  }
  ::flatbuffers::Optional<int64_t> inv_variance_tensor_uid() const {
    return GetOptional<int64_t, int64_t>(VT_INV_VARIANCE_TENSOR_UID);
  }
  bool mutate_inv_variance_tensor_uid(int64_t _inv_variance_tensor_uid) {
    return SetField<int64_t>(VT_INV_VARIANCE_TENSOR_UID, _inv_variance_tensor_uid);
  }
  int64_t scale_tensor_uid() const {
    return GetField<int64_t>(VT_SCALE_TENSOR_UID, 0);
  }
  bool mutate_scale_tensor_uid(int64_t _scale_tensor_uid = 0) {
    return SetField<int64_t>(VT_SCALE_TENSOR_UID, _scale_tensor_uid, 0);
  }
  const ::flatbuffers::Vector<int64_t> *peer_stats_tensor_uid() const {
    return GetPointer<const ::flatbuffers::Vector<int64_t> *>(VT_PEER_STATS_TENSOR_UID);
  }
  ::flatbuffers::Vector<int64_t> *mutable_peer_stats_tensor_uid() {
    return GetPointer<::flatbuffers::Vector<int64_t> *>(VT_PEER_STATS_TENSOR_UID);
  }
  int64_t dx_tensor_uid() const {
    return GetField<int64_t>(VT_DX_TENSOR_UID, 0);
  }
  bool mutate_dx_tensor_uid(int64_t _dx_tensor_uid = 0) {
    return SetField<int64_t>(VT_DX_TENSOR_UID, _dx_tensor_uid, 0);
  }
  int64_t dscale_tensor_uid() const {
    return GetField<int64_t>(VT_DSCALE_TENSOR_UID, 0);
  }
  bool mutate_dscale_tensor_uid(int64_t _dscale_tensor_uid = 0) {
    return SetField<int64_t>(VT_DSCALE_TENSOR_UID, _dscale_tensor_uid, 0);
  }
  int64_t dbias_tensor_uid() const {
    return GetField<int64_t>(VT_DBIAS_TENSOR_UID, 0);
  }
  bool mutate_dbias_tensor_uid(int64_t _dbias_tensor_uid = 0) {
    return SetField<int64_t>(VT_DBIAS_TENSOR_UID, _dbias_tensor_uid, 0);
  }
  bool Verify(::flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int64_t>(verifier, VT_DY_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_X_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_MEAN_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_INV_VARIANCE_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_SCALE_TENSOR_UID, 8) &&
           VerifyOffset(verifier, VT_PEER_STATS_TENSOR_UID) &&
           verifier.VerifyVector(peer_stats_tensor_uid()) &&
           VerifyField<int64_t>(verifier, VT_DX_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_DSCALE_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_DBIAS_TENSOR_UID, 8) &&
           verifier.EndTable();
  }
  BatchnormBackwardAttributesT *UnPack(const ::flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(BatchnormBackwardAttributesT *_o, const ::flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static ::flatbuffers::Offset<BatchnormBackwardAttributes> Pack(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormBackwardAttributesT* _o, const ::flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct BatchnormBackwardAttributesBuilder {
  typedef BatchnormBackwardAttributes Table;
  ::flatbuffers::FlatBufferBuilder &fbb_;
  ::flatbuffers::uoffset_t start_;
  void add_dy_tensor_uid(int64_t dy_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_DY_TENSOR_UID, dy_tensor_uid, 0);
  }
  void add_x_tensor_uid(int64_t x_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_X_TENSOR_UID, x_tensor_uid, 0);
  }
  void add_mean_tensor_uid(int64_t mean_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_MEAN_TENSOR_UID, mean_tensor_uid);
  }
  void add_inv_variance_tensor_uid(int64_t inv_variance_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_INV_VARIANCE_TENSOR_UID, inv_variance_tensor_uid);
  }
  void add_scale_tensor_uid(int64_t scale_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_SCALE_TENSOR_UID, scale_tensor_uid, 0);
  }
  void add_peer_stats_tensor_uid(::flatbuffers::Offset<::flatbuffers::Vector<int64_t>> peer_stats_tensor_uid) {
    fbb_.AddOffset(BatchnormBackwardAttributes::VT_PEER_STATS_TENSOR_UID, peer_stats_tensor_uid);
  }
  void add_dx_tensor_uid(int64_t dx_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_DX_TENSOR_UID, dx_tensor_uid, 0);
  }
  void add_dscale_tensor_uid(int64_t dscale_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_DSCALE_TENSOR_UID, dscale_tensor_uid, 0);
  }
  void add_dbias_tensor_uid(int64_t dbias_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormBackwardAttributes::VT_DBIAS_TENSOR_UID, dbias_tensor_uid, 0);
  }
  explicit BatchnormBackwardAttributesBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ::flatbuffers::Offset<BatchnormBackwardAttributes> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = ::flatbuffers::Offset<BatchnormBackwardAttributes>(end);
    return o;
  }
};

inline ::flatbuffers::Offset<BatchnormBackwardAttributes> CreateBatchnormBackwardAttributes(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    int64_t dy_tensor_uid = 0,
    int64_t x_tensor_uid = 0,
    ::flatbuffers::Optional<int64_t> mean_tensor_uid = ::flatbuffers::nullopt,
    ::flatbuffers::Optional<int64_t> inv_variance_tensor_uid = ::flatbuffers::nullopt,
    int64_t scale_tensor_uid = 0,
    ::flatbuffers::Offset<::flatbuffers::Vector<int64_t>> peer_stats_tensor_uid = 0,
    int64_t dx_tensor_uid = 0,
    int64_t dscale_tensor_uid = 0,
    int64_t dbias_tensor_uid = 0) {
  BatchnormBackwardAttributesBuilder builder_(_fbb);
  builder_.add_dbias_tensor_uid(dbias_tensor_uid);
  builder_.add_dscale_tensor_uid(dscale_tensor_uid);
  builder_.add_dx_tensor_uid(dx_tensor_uid);
  builder_.add_scale_tensor_uid(scale_tensor_uid);
  if(inv_variance_tensor_uid) { builder_.add_inv_variance_tensor_uid(*inv_variance_tensor_uid); }
  if(mean_tensor_uid) { builder_.add_mean_tensor_uid(*mean_tensor_uid); }
  builder_.add_x_tensor_uid(x_tensor_uid);
  builder_.add_dy_tensor_uid(dy_tensor_uid);
  builder_.add_peer_stats_tensor_uid(peer_stats_tensor_uid);
  return builder_.Finish();
}

inline ::flatbuffers::Offset<BatchnormBackwardAttributes> CreateBatchnormBackwardAttributesDirect(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    int64_t dy_tensor_uid = 0,
    int64_t x_tensor_uid = 0,
    ::flatbuffers::Optional<int64_t> mean_tensor_uid = ::flatbuffers::nullopt,
    ::flatbuffers::Optional<int64_t> inv_variance_tensor_uid = ::flatbuffers::nullopt,
    int64_t scale_tensor_uid = 0,
    const std::vector<int64_t> *peer_stats_tensor_uid = nullptr,
    int64_t dx_tensor_uid = 0,
    int64_t dscale_tensor_uid = 0,
    int64_t dbias_tensor_uid = 0) {
  auto peer_stats_tensor_uid__ = peer_stats_tensor_uid ? _fbb.CreateVector<int64_t>(*peer_stats_tensor_uid) : 0;
  return hipdnn_sdk::data_objects::CreateBatchnormBackwardAttributes(
      _fbb,
      dy_tensor_uid,
      x_tensor_uid,
      mean_tensor_uid,
      inv_variance_tensor_uid,
      scale_tensor_uid,
      peer_stats_tensor_uid__,
      dx_tensor_uid,
      dscale_tensor_uid,
      dbias_tensor_uid);
}

::flatbuffers::Offset<BatchnormBackwardAttributes> CreateBatchnormBackwardAttributes(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormBackwardAttributesT *_o, const ::flatbuffers::rehasher_function_t *_rehasher = nullptr);


inline bool operator==(const BatchnormBackwardAttributesT &lhs, const BatchnormBackwardAttributesT &rhs) {
  return
      (lhs.dy_tensor_uid == rhs.dy_tensor_uid) &&
      (lhs.x_tensor_uid == rhs.x_tensor_uid) &&
      (lhs.mean_tensor_uid == rhs.mean_tensor_uid) &&
      (lhs.inv_variance_tensor_uid == rhs.inv_variance_tensor_uid) &&
      (lhs.scale_tensor_uid == rhs.scale_tensor_uid) &&
      (lhs.peer_stats_tensor_uid == rhs.peer_stats_tensor_uid) &&
      (lhs.dx_tensor_uid == rhs.dx_tensor_uid) &&
      (lhs.dscale_tensor_uid == rhs.dscale_tensor_uid) &&
      (lhs.dbias_tensor_uid == rhs.dbias_tensor_uid);
}

inline bool operator!=(const BatchnormBackwardAttributesT &lhs, const BatchnormBackwardAttributesT &rhs) {
    return !(lhs == rhs);
}


inline BatchnormBackwardAttributesT *BatchnormBackwardAttributes::UnPack(const ::flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<BatchnormBackwardAttributesT>(new BatchnormBackwardAttributesT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void BatchnormBackwardAttributes::UnPackTo(BatchnormBackwardAttributesT *_o, const ::flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = dy_tensor_uid(); _o->dy_tensor_uid = _e; }
  { auto _e = x_tensor_uid(); _o->x_tensor_uid = _e; }
  { auto _e = mean_tensor_uid(); _o->mean_tensor_uid = _e; }
  { auto _e = inv_variance_tensor_uid(); _o->inv_variance_tensor_uid = _e; }
  { auto _e = scale_tensor_uid(); _o->scale_tensor_uid = _e; }
  { auto _e = peer_stats_tensor_uid(); if (_e) { _o->peer_stats_tensor_uid.resize(_e->size()); for (::flatbuffers::uoffset_t _i = 0; _i < _e->size(); _i++) { _o->peer_stats_tensor_uid[_i] = _e->Get(_i); } } else { _o->peer_stats_tensor_uid.resize(0); } }
  { auto _e = dx_tensor_uid(); _o->dx_tensor_uid = _e; }
  { auto _e = dscale_tensor_uid(); _o->dscale_tensor_uid = _e; }
  { auto _e = dbias_tensor_uid(); _o->dbias_tensor_uid = _e; }
}

inline ::flatbuffers::Offset<BatchnormBackwardAttributes> BatchnormBackwardAttributes::Pack(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormBackwardAttributesT* _o, const ::flatbuffers::rehasher_function_t *_rehasher) {
  return CreateBatchnormBackwardAttributes(_fbb, _o, _rehasher);
}

inline ::flatbuffers::Offset<BatchnormBackwardAttributes> CreateBatchnormBackwardAttributes(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormBackwardAttributesT *_o, const ::flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { ::flatbuffers::FlatBufferBuilder *__fbb; const BatchnormBackwardAttributesT* __o; const ::flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _dy_tensor_uid = _o->dy_tensor_uid;
  auto _x_tensor_uid = _o->x_tensor_uid;
  auto _mean_tensor_uid = _o->mean_tensor_uid;
  auto _inv_variance_tensor_uid = _o->inv_variance_tensor_uid;
  auto _scale_tensor_uid = _o->scale_tensor_uid;
  auto _peer_stats_tensor_uid = _o->peer_stats_tensor_uid.size() ? _fbb.CreateVector(_o->peer_stats_tensor_uid) : 0;
  auto _dx_tensor_uid = _o->dx_tensor_uid;
  auto _dscale_tensor_uid = _o->dscale_tensor_uid;
  auto _dbias_tensor_uid = _o->dbias_tensor_uid;
  return hipdnn_sdk::data_objects::CreateBatchnormBackwardAttributes(
      _fbb,
      _dy_tensor_uid,
      _x_tensor_uid,
      _mean_tensor_uid,
      _inv_variance_tensor_uid,
      _scale_tensor_uid,
      _peer_stats_tensor_uid,
      _dx_tensor_uid,
      _dscale_tensor_uid,
      _dbias_tensor_uid);
}

}  // namespace data_objects
}  // namespace hipdnn_sdk

#endif  // FLATBUFFERS_GENERATED_BATCHNORMBACKWARDATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_
