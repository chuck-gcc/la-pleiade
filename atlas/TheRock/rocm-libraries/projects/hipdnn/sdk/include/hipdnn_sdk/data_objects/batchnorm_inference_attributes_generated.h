// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_BATCHNORMINFERENCEATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_
#define FLATBUFFERS_GENERATED_BATCHNORMINFERENCEATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_

#include "flatbuffers/flatbuffers.h"

// Ensure the included flatbuffers.h is the same version as when this file was
// generated, otherwise it may not be compatible.
static_assert(FLATBUFFERS_VERSION_MAJOR == 25 &&
              FLATBUFFERS_VERSION_MINOR == 9 &&
              FLATBUFFERS_VERSION_REVISION == 23,
             "Non-compatible flatbuffers version included");

namespace hipdnn_sdk {
namespace data_objects {

struct BatchnormInferenceAttributes;
struct BatchnormInferenceAttributesBuilder;
struct BatchnormInferenceAttributesT;

bool operator==(const BatchnormInferenceAttributesT &lhs, const BatchnormInferenceAttributesT &rhs);
bool operator!=(const BatchnormInferenceAttributesT &lhs, const BatchnormInferenceAttributesT &rhs);

struct BatchnormInferenceAttributesT : public ::flatbuffers::NativeTable {
  typedef BatchnormInferenceAttributes TableType;
  int64_t x_tensor_uid = 0;
  int64_t mean_tensor_uid = 0;
  int64_t inv_variance_tensor_uid = 0;
  int64_t scale_tensor_uid = 0;
  int64_t bias_tensor_uid = 0;
  int64_t y_tensor_uid = 0;
};

struct BatchnormInferenceAttributes FLATBUFFERS_FINAL_CLASS : private ::flatbuffers::Table {
  typedef BatchnormInferenceAttributesT NativeTableType;
  typedef BatchnormInferenceAttributesBuilder Builder;
  enum FlatBuffersVTableOffset FLATBUFFERS_VTABLE_UNDERLYING_TYPE {
    VT_X_TENSOR_UID = 4,
    VT_MEAN_TENSOR_UID = 6,
    VT_INV_VARIANCE_TENSOR_UID = 8,
    VT_SCALE_TENSOR_UID = 10,
    VT_BIAS_TENSOR_UID = 12,
    VT_Y_TENSOR_UID = 14
  };
  int64_t x_tensor_uid() const {
    return GetField<int64_t>(VT_X_TENSOR_UID, 0);
  }
  bool mutate_x_tensor_uid(int64_t _x_tensor_uid = 0) {
    return SetField<int64_t>(VT_X_TENSOR_UID, _x_tensor_uid, 0);
  }
  int64_t mean_tensor_uid() const {
    return GetField<int64_t>(VT_MEAN_TENSOR_UID, 0);
  }
  bool mutate_mean_tensor_uid(int64_t _mean_tensor_uid = 0) {
    return SetField<int64_t>(VT_MEAN_TENSOR_UID, _mean_tensor_uid, 0);
  }
  int64_t inv_variance_tensor_uid() const {
    return GetField<int64_t>(VT_INV_VARIANCE_TENSOR_UID, 0);
  }
  bool mutate_inv_variance_tensor_uid(int64_t _inv_variance_tensor_uid = 0) {
    return SetField<int64_t>(VT_INV_VARIANCE_TENSOR_UID, _inv_variance_tensor_uid, 0);
  }
  int64_t scale_tensor_uid() const {
    return GetField<int64_t>(VT_SCALE_TENSOR_UID, 0);
  }
  bool mutate_scale_tensor_uid(int64_t _scale_tensor_uid = 0) {
    return SetField<int64_t>(VT_SCALE_TENSOR_UID, _scale_tensor_uid, 0);
  }
  int64_t bias_tensor_uid() const {
    return GetField<int64_t>(VT_BIAS_TENSOR_UID, 0);
  }
  bool mutate_bias_tensor_uid(int64_t _bias_tensor_uid = 0) {
    return SetField<int64_t>(VT_BIAS_TENSOR_UID, _bias_tensor_uid, 0);
  }
  int64_t y_tensor_uid() const {
    return GetField<int64_t>(VT_Y_TENSOR_UID, 0);
  }
  bool mutate_y_tensor_uid(int64_t _y_tensor_uid = 0) {
    return SetField<int64_t>(VT_Y_TENSOR_UID, _y_tensor_uid, 0);
  }
  bool Verify(::flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int64_t>(verifier, VT_X_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_MEAN_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_INV_VARIANCE_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_SCALE_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_BIAS_TENSOR_UID, 8) &&
           VerifyField<int64_t>(verifier, VT_Y_TENSOR_UID, 8) &&
           verifier.EndTable();
  }
  BatchnormInferenceAttributesT *UnPack(const ::flatbuffers::resolver_function_t *_resolver = nullptr) const;
  void UnPackTo(BatchnormInferenceAttributesT *_o, const ::flatbuffers::resolver_function_t *_resolver = nullptr) const;
  static ::flatbuffers::Offset<BatchnormInferenceAttributes> Pack(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormInferenceAttributesT* _o, const ::flatbuffers::rehasher_function_t *_rehasher = nullptr);
};

struct BatchnormInferenceAttributesBuilder {
  typedef BatchnormInferenceAttributes Table;
  ::flatbuffers::FlatBufferBuilder &fbb_;
  ::flatbuffers::uoffset_t start_;
  void add_x_tensor_uid(int64_t x_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_X_TENSOR_UID, x_tensor_uid, 0);
  }
  void add_mean_tensor_uid(int64_t mean_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_MEAN_TENSOR_UID, mean_tensor_uid, 0);
  }
  void add_inv_variance_tensor_uid(int64_t inv_variance_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_INV_VARIANCE_TENSOR_UID, inv_variance_tensor_uid, 0);
  }
  void add_scale_tensor_uid(int64_t scale_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_SCALE_TENSOR_UID, scale_tensor_uid, 0);
  }
  void add_bias_tensor_uid(int64_t bias_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_BIAS_TENSOR_UID, bias_tensor_uid, 0);
  }
  void add_y_tensor_uid(int64_t y_tensor_uid) {
    fbb_.AddElement<int64_t>(BatchnormInferenceAttributes::VT_Y_TENSOR_UID, y_tensor_uid, 0);
  }
  explicit BatchnormInferenceAttributesBuilder(::flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ::flatbuffers::Offset<BatchnormInferenceAttributes> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = ::flatbuffers::Offset<BatchnormInferenceAttributes>(end);
    return o;
  }
};

inline ::flatbuffers::Offset<BatchnormInferenceAttributes> CreateBatchnormInferenceAttributes(
    ::flatbuffers::FlatBufferBuilder &_fbb,
    int64_t x_tensor_uid = 0,
    int64_t mean_tensor_uid = 0,
    int64_t inv_variance_tensor_uid = 0,
    int64_t scale_tensor_uid = 0,
    int64_t bias_tensor_uid = 0,
    int64_t y_tensor_uid = 0) {
  BatchnormInferenceAttributesBuilder builder_(_fbb);
  builder_.add_y_tensor_uid(y_tensor_uid);
  builder_.add_bias_tensor_uid(bias_tensor_uid);
  builder_.add_scale_tensor_uid(scale_tensor_uid);
  builder_.add_inv_variance_tensor_uid(inv_variance_tensor_uid);
  builder_.add_mean_tensor_uid(mean_tensor_uid);
  builder_.add_x_tensor_uid(x_tensor_uid);
  return builder_.Finish();
}

::flatbuffers::Offset<BatchnormInferenceAttributes> CreateBatchnormInferenceAttributes(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormInferenceAttributesT *_o, const ::flatbuffers::rehasher_function_t *_rehasher = nullptr);


inline bool operator==(const BatchnormInferenceAttributesT &lhs, const BatchnormInferenceAttributesT &rhs) {
  return
      (lhs.x_tensor_uid == rhs.x_tensor_uid) &&
      (lhs.mean_tensor_uid == rhs.mean_tensor_uid) &&
      (lhs.inv_variance_tensor_uid == rhs.inv_variance_tensor_uid) &&
      (lhs.scale_tensor_uid == rhs.scale_tensor_uid) &&
      (lhs.bias_tensor_uid == rhs.bias_tensor_uid) &&
      (lhs.y_tensor_uid == rhs.y_tensor_uid);
}

inline bool operator!=(const BatchnormInferenceAttributesT &lhs, const BatchnormInferenceAttributesT &rhs) {
    return !(lhs == rhs);
}


inline BatchnormInferenceAttributesT *BatchnormInferenceAttributes::UnPack(const ::flatbuffers::resolver_function_t *_resolver) const {
  auto _o = std::unique_ptr<BatchnormInferenceAttributesT>(new BatchnormInferenceAttributesT());
  UnPackTo(_o.get(), _resolver);
  return _o.release();
}

inline void BatchnormInferenceAttributes::UnPackTo(BatchnormInferenceAttributesT *_o, const ::flatbuffers::resolver_function_t *_resolver) const {
  (void)_o;
  (void)_resolver;
  { auto _e = x_tensor_uid(); _o->x_tensor_uid = _e; }
  { auto _e = mean_tensor_uid(); _o->mean_tensor_uid = _e; }
  { auto _e = inv_variance_tensor_uid(); _o->inv_variance_tensor_uid = _e; }
  { auto _e = scale_tensor_uid(); _o->scale_tensor_uid = _e; }
  { auto _e = bias_tensor_uid(); _o->bias_tensor_uid = _e; }
  { auto _e = y_tensor_uid(); _o->y_tensor_uid = _e; }
}

inline ::flatbuffers::Offset<BatchnormInferenceAttributes> BatchnormInferenceAttributes::Pack(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormInferenceAttributesT* _o, const ::flatbuffers::rehasher_function_t *_rehasher) {
  return CreateBatchnormInferenceAttributes(_fbb, _o, _rehasher);
}

inline ::flatbuffers::Offset<BatchnormInferenceAttributes> CreateBatchnormInferenceAttributes(::flatbuffers::FlatBufferBuilder &_fbb, const BatchnormInferenceAttributesT *_o, const ::flatbuffers::rehasher_function_t *_rehasher) {
  (void)_rehasher;
  (void)_o;
  struct _VectorArgs { ::flatbuffers::FlatBufferBuilder *__fbb; const BatchnormInferenceAttributesT* __o; const ::flatbuffers::rehasher_function_t *__rehasher; } _va = { &_fbb, _o, _rehasher}; (void)_va;
  auto _x_tensor_uid = _o->x_tensor_uid;
  auto _mean_tensor_uid = _o->mean_tensor_uid;
  auto _inv_variance_tensor_uid = _o->inv_variance_tensor_uid;
  auto _scale_tensor_uid = _o->scale_tensor_uid;
  auto _bias_tensor_uid = _o->bias_tensor_uid;
  auto _y_tensor_uid = _o->y_tensor_uid;
  return hipdnn_sdk::data_objects::CreateBatchnormInferenceAttributes(
      _fbb,
      _x_tensor_uid,
      _mean_tensor_uid,
      _inv_variance_tensor_uid,
      _scale_tensor_uid,
      _bias_tensor_uid,
      _y_tensor_uid);
}

}  // namespace data_objects
}  // namespace hipdnn_sdk

#endif  // FLATBUFFERS_GENERATED_BATCHNORMINFERENCEATTRIBUTES_HIPDNN_SDK_DATA_OBJECTS_H_
